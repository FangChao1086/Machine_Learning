# 计算机视觉知识点
* [常用图像数据集](#常用图像数据集)
* [形态学计算_Morphology](#形态学计算_Morphology)
* [R-CNN](#R-CNN)
* [Fast_RCNN](#Fast_RCNN)
* [Faster_RCNN](#Faster_RCNN)
* [Mask_RCNN](#Mask_RCNN)
* [Yolo](#Yolo)
* [SSD](#SSD)

<span id="常用图像数据集"></span>
## 常用图像数据集
* **ImageNet ILSVC 2012**
  * 一千万图像，1000类；标定每张图片中**物体的类别**
* **PASCAL VOC 2007**
  * 一万图像，20类；标定每张图片中**物体的类别和位置**
* **PASCAL VOC 2011**
  * 一万一千图像，21类（20物体类+1其他背景类）

<span id="形态学计算_Morphology"></span>
## 形态学计算_Morphology
**站在图像（白色部分）的角度考虑侵蚀或者扩张**  
* Erosion
![erosion](https://i.ibb.co/2YRpPCL/erosion.png)
* Dilation
![dilation](https://i.ibb.co/Yp2jH6D/dilation.png)
* Opening
  * 先侵蚀，后扩张
  ![opening](https://i.ibb.co/xCsqPZY/opening.png)
* Closing
  * 先扩张，后侵蚀
  ![closing](https://i.ibb.co/SP7M4BZ/closing.png)

[参考链接：基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN](https://www.cnblogs.com/skyfsm/p/6806246.html)
<span id="R-CNN"></span>
## R-CNN
许多候选框（比如两千个）-->resize,CNN-->得到每个候选框的特征-->分类+回归  
![RCNN](https://i.ibb.co/p2qbQ5P/RCNN.png)  

### 步骤：   
* **候选框生成**：在图像中提取约1000-**2000个候选区域（ROI）** (方法**selective search**)  
* **提取特征**：将每个候选区域**缩放至相同大小**，然后对每个区域进行特征提取（采用**CNN**提取4096维）  
* **类别判断**：提取出的特征送入每一类的SVM 分类器，判别是否属于该类
* **位置精修**：对于属于某一特征的候选框，用回归器进一步调整其位置

**训练：使用ImageNet ILSVC 2012进行有监督预训练，而后用PASCAL VOC 2007调优参数，最后在PASCAL VOC 2007上评测**

### 算法实现
* 网络架构（选择Alexnet），对每个输入候选框得到一个4096维的特征向量
  * Alexnet精度：58.5%；
  * VGG精度：66%，选择小卷积核，较小的跨步，计算量是Alexnet的7倍  
  ![Alextnet_layer](https://i.ibb.co/j88jt0q/alexnet.jpg)  
  ![Alextnet_cnn](https://i.ibb.co/QC5fvkQ/Alexnet-cnn.jpg)  

* **有监督预训练**：
  * 也就是迁移学习。**简单来说，就是把一个任务训练好的参数，拿到另一个任务，作为神经网络的初始参数值**，这样训练出来的参数值比采用随机初始化的方法，精度会有很大提高。  
  * 举例：先需要训练一个CNN，用于人脸的年龄识别；当有新任务，人脸识别性别，此时就可以利用已经训练好的年龄CNN模型，去掉最后一层，然后其他层的网络参数直接复制过来，继续进行训练，输出性别即可。  
  * **目的：解决物体检测的一个难点，物体标签训练数据少，直接采用随机初始化CNN参数的，目前的训练数据量是远远不够的**
  * 具体实现：在ImagNet上进行有监督的预训练
  ![RCNN-pre-train](https://i.ibb.co/kSSYWrf/RCNN-pre-train.jpg)
  

### 框的重叠度评估：IOU
![IOU](https://i.ibb.co/N7bdvjs/IOU.png)  
算法检测的定位框与人工标注的数据不可能完全匹配，IOU是为了评估两个框的重叠度

### 非极大值抑制：NMS 
![NMS](https://i.ibb.co/z6CxXyn/NMS.png)  
RCNN定位一辆车，可能找出很多框，有些重复过大的需要去除，于是有了NMS；  

假设有6个矩形框，从小到大概率属于车辆的框分别是A、B、C、D、E、F；具体NMS做法：
* 从最大概率的F框开始，判断A-E与F的重叠度IOU是否大于某个阈值
* 假设B、D与F的IOU大于，则丢弃B、D;并标记第一个矩形框F，保留
* 剩下的A、C、E，选择概率大的E，判断A,C与E的重叠度，当重叠度IOU大于阈值，则丢弃A,C；并标记第二个矩形框E，保留

问题：候选区域重叠，产生重复计算

<span id="Fast_RCNN"></span>
## Fast_RCNN  
一张完整图片-->CNN-->得到每张候选框的特征-->分类+回归  
改进：无需resize，对图片输入大小不限制  

**RCNN+SPP Net(空间金字塔池化)**  
* SPP Net（ROI pooling）
  * 输入：任意尺寸
  * 输出：固定尺寸
  * 只需要**对原图一次卷积提取特征**，节省了大量的计算时间
* Faster_RCNN将bbox regression放进了神经网络内部

<details><summary>步骤：</summary>  
 
　　1.	在图像中确定约1000-2000个候选框 (使用选择性搜索)  
　　2.	对整张图片输进CNN，得到feature map  
　　3.	找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层  
　　4.	对候选框中提取出的特征，使用分类器判别是否属于一个特定类   
　　5.	对于属于某一特征的候选框，用回归器进一步调整其位置  </details>

<span id="Faster_RCNN"></span>
## Faster_RCNN
改进：抛弃选择性搜索，自动提取候选区域（RPN网络）

<details><summary>步骤：</summary>  
 
　　1.	对整张图片输进CNN，得到feature map  
　　2.	卷积特征输入到RPN，得到候选框的特征信息  
　　3.	对候选框中提取出的特征，使用分类器判别是否属于一个特定类   
　　4.	对于属于某一特征的候选框，用回归器进一步调整其位置  </details>

<span id="Mask_RCNN"></span>
## Mask_RCNN
[Github：Mask_RCNN](https://github.com/matterport/Mask_RCNN)

<span id="Yolo"></span>
## Yolo

<span id="SSD"></span>
## SSD
* 多尺度
* 卷积检测
* 先验框（default box）

### 网络框架
![网络框架](https://i.ibb.co/kyctDkY/ssd-net.jpg)  

### 训练目标
![ssd_训练目标](https://i.ibb.co/x5nMCHn/ssd-loss.jpg)  
$x_{i j}^{p}=1$：第i个框与类别p的第j个真实框是一致的  
损失函数：  
$$L(x, c, l, g)=L_{c o n f}(x, c)+\alpha L_{l o c}(x, l, g)$$  
定位损失函数是预测框与真实框的L2损失：  
$$L_{l o c}(x, l, g)=\frac{1}{2} \sum_{i, j} x_{i j}^{p}\|\|l_{i}-g_{j}^{p}\|\|_ {2}^{2}$$  
分类损失：  
$$L_{conf}(x, c)=-\sum_{i \in P o s}^{N} x_{i j}^{p} \log \left(\hat{c}_ {i}^{p}\right)-\sum_{i \in N e g} \log \left(\hat{c}_ {i}^{0}\right)$$  

