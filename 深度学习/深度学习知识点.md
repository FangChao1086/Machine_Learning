# 深度学习知识点
* [Dropout](#Dropout)

<span id="Dropout"></span>
## Dropout
我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征  
###dropout可以解决过拟合的原因：
1. 取平均的作用  
> 整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合

2. 减少神经元之间复杂的共适应关系
