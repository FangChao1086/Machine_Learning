{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division        # 精确除法\n",
    "from __future__ import absolute_import # 绝对路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor? Flow?\n",
    "`tensor`是张量的意思,顾名思义,是一个能够存储多维数组的`tensorflow`数据结构,它的元素可以是`int`类型,`float`类型,`bool`类型,还有`string`类型等等.\n",
    "\n",
    "`flow`是流动的意思,`tensor`为什么可以`flow`呢?我们通过官网的例子来一探究竟."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(32)\n",
    "b = tf.constant(10)\n",
    "c = tf.add(a, b)\n",
    "sess = tf.Session()\n",
    "print(sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**上面**这段代码看上去非常简单,从结果上来看是在计算一个数学表达式`32+10` 的值,却也完整展示了`tensorflow`运行的基本构架.\n",
    "\n",
    "首先,第一行`a = tf.constant(32)`定义了一个常量`tensor`,它的值为`32`,第二行也是类似.在我们运行`tensorflow`程序的时候,任何数据都必须转换成`tensor`类型才能够进入这个系统,我们先牢记这一点,之后会对它进行优缺点分析.那么现在我们就有了两个常量`tensor`.\n",
    "\n",
    "但是仅仅定义了两个用于存储数据的`tensor`毫无用处,我们希望能够实现的是这两个数的加法运算.相信大家小时候学数学加减法的时候老师都会在黑板上作出这样的图:\n",
    "\n",
    "<img src=\"https://image.ibb.co/jmcSfG/basic_add.png\" width=\"200\">\n",
    "\n",
    "这张图揭示了加法运算的过程,通过`+`这个符号将两个数连接起来,并生成了一个新的数.\n",
    "\n",
    "这正是`tensorflow`致力于实现的目标,通过`tf.add()`这个函数,将两个`tensor`连接起来并生成了一个新的`tensor`:`c`.实际上,定义在一个或者多个`tensor`上的函数在`tensorflow`中被封装成`operator`的概念.还可以发现,加法只是一个关于两个数和一个操作的关系,对于输入的数据是`1,2`还是`32,10`完全不会有任何本质改变. 因此, 整个计算图以符号计算的定义方式, 被封装成了`Graph`,也就是图的概念.\n",
    "\n",
    "<img src=\"https://image.ibb.co/gjZgSc/tf_add_graph.png\" width=\"200\">\n",
    "\n",
    "到这里, 我们通过构建两个`tensor`以及一个`operation`完成了一个`Graph`的创建. 这些是我们运行`tensorflow`程序的标准步骤, 但还并没有结束. 大家可以尝试运行下面这行代码, 看看它的输出是什么."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时相信我们中的大部分都会心里产生巨大的疑惑, 怎么会输出这么一堆看不懂的东西, 我只是想让它像定义时那样输出`32, 10, 42`就好了啊, 难道我的`print`函数坏掉了?无论你如何进行尝试, 你会发现都没有出现你想要的结果, 因为就像刚才说的, 在`tensorflow`下, 所有的`tensor`都是一种符号, 用来构建整个`Graph`的, 它是什么值并不重要, 所以就无法在构建图之后进行打印看它的值了.\n",
    "\n",
    "但这显然不是我们想要看到的, 如何才能正确打印这些值呢? 事实上, `tensorflow`将构建图和执行图分成了两个独立的步骤, 也就是说你要先构建一个完整的计算图, 此时你无法获取图的具体信息, 但是随后你可以开始进入图的执行过程, 这样你就可以获得图执行时每个`tensor`的具体值了. 怎样进入图的执行呢?\n",
    "\n",
    "### 开启`Session`(会话)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单的`sess = tf.Session()`就可以搞定. 开启会话后, 我们就可以执行图中的各个`tensor`了, 用的正是`sess.run()`这个语句.\n",
    "\n",
    "现在我们可以试试下面这些命令了:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[32, 10]\n",
      "[32, 10, 42]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(a))\n",
    "print(sess.run([a, b]))\n",
    "print(sess.run([a, b, c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以将执行图的结果保存到正常的变量中, `tensorflow`称这个过程为`fetch`. 运行下面的命令, 相信你会对`fetch`有一个初步的了解."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int32'>\n",
      "32\n",
      "<class 'list'>\n",
      "32 10 42\n"
     ]
    }
   ],
   "source": [
    "py_a = sess.run(a)\n",
    "print(type(py_a))\n",
    "print(py_a)\n",
    "py_r = sess.run([a, b, c])\n",
    "print(type(py_r))\n",
    "print(py_r[0], py_r[1], py_r[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Tensors`\n",
    "`tensor`可以有很多形式."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n",
      "True\n",
      "[1 2]\n",
      "[1. 2.]\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello, Tensorflow!')\n",
    "boolean = tf.constant(True)\n",
    "int_array = tf.constant([1, 2], dtype=tf.int32)\n",
    "float_array = tf.constant([1, 2], dtype=tf.float32)\n",
    "\n",
    "print(sess.run(hello))\n",
    "print(sess.run(boolean))\n",
    "print(sess.run(int_array))\n",
    "print(sess.run(float_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习1\n",
    "构造一个`tensor`, 使得输出一个`numpy`矩阵[[1 0] [0 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 答案1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "mat = tf.constant([[1,0],[0,1]])\n",
    "print(sess.run(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensor`还可以有**名字**, 在定义每个`tensor`的时候添加参数**`name`**的值就可以.这是一个可选参数, 不过在后面有很大的意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor Hello:0: b'Hello'\n",
      "tensor World:0: b'World'\n"
     ]
    }
   ],
   "source": [
    "my_name_is_hello = tf.constant('Hello', name='Hello')\n",
    "my_name_is_world = tf.constant('World', name='World')\n",
    "\n",
    "print('tensor {}: {}'.format(my_name_is_hello.name, sess.run(my_name_is_hello)))\n",
    "print('tensor {}: {}'.format(my_name_is_world.name, sess.run(my_name_is_world)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Operations`\n",
    "`tensorflow`原生支持很多的`operation`, 以后我们将用`op`来简称`operation`. 注意, `op`也可以有名字用来标识."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "22\n",
      "320\n",
      "3.2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "d = tf.add_n([a, b, b])\n",
    "e = tf.subtract(a, b)\n",
    "f = tf.multiply(a, b)\n",
    "g = tf.divide(a, b)\n",
    "h = tf.mod(a, b)\n",
    "\n",
    "print(sess.run(d))\n",
    "print(sess.run(e))\n",
    "print(sess.run(f))\n",
    "print(sess.run(g))\n",
    "print(sess.run(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5514267\n",
      "1.0317434\n",
      "-0.043819606\n"
     ]
    }
   ],
   "source": [
    "a_float = tf.cast(a, dtype=tf.float32)\n",
    "b_float = tf.cast(b, dtype=tf.float32)\n",
    "\n",
    "i = tf.sin(a_float)\n",
    "j = tf.exp(tf.divide(1.0, a_float))\n",
    "k = tf.add(i, tf.log(i))\n",
    "\n",
    "print(sess.run(i))\n",
    "print(sess.run(j))\n",
    "print(sess.run(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习2\n",
    "构造一个`tensor`, 它的值等于$sigmoid(b)$, `sigmoid`函数如下定义\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation}\n",
    "$$\n",
    "它的函数图像(摘自[Wiki](https://en.wikipedia.org/wiki/Sigmoid_function))如下所示:\n",
    "<img src=\"https://image.ibb.co/cH5c0x/practice2_sigmoid.png\" width=\"360\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 答案2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999546\n"
     ]
    }
   ],
   "source": [
    "sigmoid = tf.divide(1.0, tf.add(1.0, tf.exp(-b_float)))\n",
    "print(sess.run(sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以通过`reshape`改变形状\n",
    "- `tensorflow`支持矩阵操作,`broadcast`机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[ 1  3  5]\n",
      " [ 7  9 11]]\n",
      "[[15 21 27]\n",
      " [31 45 59]]\n",
      "[[1 4]\n",
      " [3 8]]\n"
     ]
    }
   ],
   "source": [
    "mat_a = tf.constant([1, 2, 3, 4])\n",
    "mat_a = tf.reshape(mat_a, (2, 2))\n",
    "mat_b = tf.constant([1, 3, 5, 7, 9, 11])\n",
    "mat_b = tf.reshape(mat_b, (2, 3))\n",
    "vec_a = tf.constant([1, 2])\n",
    "\n",
    "mat_c = tf.matmul(mat_a, mat_b)\n",
    "mat_d = tf.multiply(mat_a, vec_a)\n",
    "\n",
    "print(sess.run(mat_a))\n",
    "print(sess.run(mat_b))\n",
    "print(sess.run(mat_c))\n",
    "print(sess.run(mat_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy_like `tensors`\n",
    "`tensorflow`采用了很多类似于`numpy`的数据定义方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros:\n",
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "\n",
      "zeros_like:\n",
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "\n",
      "ones_like:\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "\n",
      "fill:\n",
      "[[2 2 2 2]\n",
      " [2 2 2 2]]\n",
      "\n",
      "linspace:\n",
      "[1. 2. 3. 4. 5.]\n",
      "\n",
      "range:\n",
      "[ 3  6  9 12 15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zeros = tf.zeros((2, 3), dtype=tf.int32)\n",
    "zeros_like = tf.zeros_like(zeros)\n",
    "ones_like = tf.ones_like(zeros)\n",
    "fill = tf.fill((2, 4), 2)\n",
    "linspace = tf.linspace(1.0, 5.0, 5)\n",
    "ranger = tf.range(3, 18, delta=3)\n",
    "\n",
    "print('{}:\\n{}\\n'.format('zeros', sess.run(zeros)))\n",
    "print('{}:\\n{}\\n'.format('zeros_like', sess.run(zeros_like)))\n",
    "print('{}:\\n{}\\n'.format('ones_like', sess.run(ones_like)))\n",
    "print('{}:\\n{}\\n'.format('fill', sess.run(fill)))\n",
    "print('{}:\\n{}\\n'.format('linspace', sess.run(linspace)))\n",
    "print('{}:\\n{}\\n'.format('range', sess.run(ranger)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `random tensors`\n",
    "`tensorflow`有很多`random`算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0\n",
      "rand_normal: 0.7901\n",
      "truncated_normal: 1.4687\n",
      "rand_uniform: 0.4510\n",
      "time: 1\n",
      "rand_normal: -1.5295\n",
      "truncated_normal: 0.7395\n",
      "rand_uniform: 0.2626\n",
      "time: 2\n",
      "rand_normal: 0.9341\n",
      "truncated_normal: -0.5260\n",
      "rand_uniform: 0.6590\n",
      "time: 3\n",
      "rand_normal: -0.4914\n",
      "truncated_normal: -0.1449\n",
      "rand_uniform: 0.2189\n",
      "time: 4\n",
      "rand_normal: 1.8895\n",
      "truncated_normal: 1.1365\n",
      "rand_uniform: 0.8893\n"
     ]
    }
   ],
   "source": [
    "rand_normal = tf.random_normal((), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None)\n",
    "truncated_normal = tf.truncated_normal((), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None)\n",
    "rand_uniform = tf.random_uniform((), minval=0.0, maxval=1.0, dtype=tf.float32, seed=None)\n",
    "\n",
    "for i in range(5):\n",
    "    print('time: %d' % i)\n",
    "    print('rand_normal: %.4f' % sess.run(rand_normal))\n",
    "    print('truncated_normal: %.4f' % sess.run(truncated_normal))\n",
    "    print('rand_uniform: %.4f' % sess.run(rand_uniform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关闭`Session`\n",
    "`session`可以打开就需要被关闭, 用下面这行命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "前面的这些是`tensorflow`的一些常量`tensor`, 通常来说它们一旦被定义就无法更改. 在我们训练机器学习模型的时候, 最重要的一步便是更新参数, 这些常量`tensor`无法满足. \n",
    "\n",
    "那么我们就需要变量(`variables`).先看看变量如何定义."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_a = tf.Variable(0, dtype=tf.int32)\n",
    "var_b = tf.Variable([1, 2], dtype=tf.float32)\n",
    "var_w = tf.Variable(tf.zeros((1024, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**每个**变量都有一个`initializer`的函数, 规定这个变量的初始值是什么. 因此, 在执行图的过程中必须要**先初始化**变量后才能够使用. 可以通过下面的这些方法进行初始化\n",
    "\n",
    "在此之前, 我们先了解一下`tensorflow`的交互式`session`:**`InteractiveSession()`**,在处理`variable`的时候, 它比普通的`Session`更为灵活一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##开启交互式`session`\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "##一次性初始化所有的变量\n",
    "init = tf.global_variables_initializer()\n",
    "###一般`session`的方法\n",
    "sess.run(init)\n",
    "###`InteractiveSession`的方法\n",
    "init.run()\n",
    "\n",
    "##初始化某些变量\n",
    "init_ab = tf.variables_initializer([var_a, var_b])\n",
    "init_ab.run()\n",
    "\n",
    "## 初始化某个变量\n",
    "var_w.initializer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化完成后仍然不能打印值, 需要用`session`去`run`这个`variable`,或者是调用`InteractiveSession`下面的**`eval()`**函数, 大家观察一下下面输出的不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=() dtype=int32_ref>\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(10)\n",
    "sess.run(W.initializer)\n",
    "print(W)\n",
    "print(sess.run(W))\n",
    "print(W.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`assign`**是为`variable`赋值的一个`op`,大家可以看下面的代码来理解`operation`和`assign`的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "W.assign(100)\n",
    "W.initializer.run()\n",
    "print(W.eval(sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "assign_op = W.assign(100)\n",
    "W.initializer.run()\n",
    "assign_op.eval()\n",
    "print(W.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`assign_add`**和**`assign_sub`**对应与我们平常理解的`i++`和`i--`, 也是`variable`的常用`op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "30\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "assign_add = W.assign_add(10)\n",
    "assign_sub = W.assign_sub(2)\n",
    "\n",
    "W.initializer.run()\n",
    "print(assign_add.eval())\n",
    "print(assign_add.eval())\n",
    "print(assign_sub.eval())\n",
    "print(W.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name_scope和variable_scope\n",
    "\n",
    "我们可以给一些 tensor 添加一个名称域，这样所有的变量名称都有一个共同的前缀. \n",
    "\n",
    "我们可以通过`tf.name_scope`或者`tf.variable_scope`来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_scope/Variable:0\n",
      "name_scope/Variable_1:0\n",
      "var_scope/Variable:0\n",
      "var_scope/Variable_1:0\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('name_scope'):\n",
    "    var_a = tf.Variable(0, dtype=tf.int32)\n",
    "    var_b = tf.Variable([1, 2], dtype=tf.float32)\n",
    "with tf.variable_scope('var_scope'):\n",
    "    var_c = tf.Variable(0, dtype=tf.int32)\n",
    "    var_d = tf.Variable([1, 2], dtype=tf.float32)\n",
    "print(var_a.name)\n",
    "print(var_b.name)\n",
    "print(var_c.name)\n",
    "print(var_d.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "在前面我们介绍计算图的时候, 我们注意到构建图的时候可以脱离具体值进行定义它的整体结构, 在运行的时候可以根据需要带入具体的数值. 可是前面我们定义的常量`tensor`以及变量`tensor`都需要一个初始值. 因此, 为了更加契合图的构建过程, `tensorflow`引入了一个**占位符**.(`placeholder`)的概念. 字如其面, 它只是占着构建图的一个位置,没有具体数值, 但必须要有具体的类型以及形状. 我们来看看这个古怪的东西是如何定义的吧."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##定义一个占位符\n",
    "##`tf.placeholder(dtype, shape=None, name=None)`\n",
    "\n",
    "# 定义一个`float32`型的占位符,它是一个长为3的向量\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "\n",
    "# 定义一个`bool`型的占位符, 它是一个`1x2`的矩阵\n",
    "b = tf.placeholder(tf.bool, shape=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们还像之前那样企图用`a.eval()`的话, 就会体会到`placeholder`的特别之处, 因为它真的没有任何值! 实际上,在执行图的过程中, 我们必须要用字典的方式给`placeholder`喂入具体值, 这个过程称为**`feed`**. \n",
    "\n",
    "表现在程序中, 就是我们在获取一个占位符的值的时候, 需要给`run()`增加一个`feed_dict`的参数, 这个参数是一个`dict`, 它的`key`是占位符的变量名, 它的`val`是需要喂入的具体值. 当然, 这个字典可以有很多个`key`, 也就是说可以一次喂入很多个占位符."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "[array([1., 2., 3.], dtype=float32), array([[ True, False]])]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(a, feed_dict={a: [1, 2, 3]}))\n",
    "print(sess.run([a, b], feed_dict={a: [1, 2, 3], b: [[True, False]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "占位符也是一个`tensor`,因此它可以被`op`作用, 可以和其他`tensor`混合在一起使用. 这样, 图的构建也就完整了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习3\n",
    "构造一个数值占位符, 当喂入的元素是1, 2, 4, 8时, 输出这个占位符的平方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 答案3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "4.0\n",
      "16.0\n",
      "64.0\n",
      "1.0\n",
      "4.0\n",
      "9.0\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "square = tf.square(a)\n",
    "for i in [1, 2, 4, 8]:\n",
    "    print(square.eval(feed_dict={a:i}))\n",
    "    \n",
    "for i in [1,2,3,4]:\n",
    "    print(sess.run(a, feed_dict={a:i*i}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Graph\n",
    "最后我们再来看一下`tensorflow`里图的概念. 前面说了, 在执行图之前, 需要将整个计算图都构建完成, 那么我们如何才能获得这个完整的图呢? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x0000019F701CBA90>\n"
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了, 得到这个图之后, 我们当然可以往前回溯我们创建过的图的每一个节点, 通过`g.get_operations()`就可以查到所有的节点. 我们还可以通过`g.get_tensor_by_name()`获得对应`name`的`tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const\n",
      "Const_1\n",
      "Add\n",
      "Const_2\n",
      "Const_3\n",
      "Const_4\n",
      "Const_5\n",
      "Const_6\n",
      "Hello\n",
      "World\n",
      "AddN\n",
      "Sub\n",
      "Mul\n",
      "truediv/Cast\n",
      "truediv/Cast_1\n",
      "truediv\n",
      "FloorMod\n",
      "Cast\n",
      "Cast_1\n",
      "Sin\n",
      "truediv_1/x\n",
      "truediv_1\n",
      "Exp\n",
      "Log\n",
      "Add_1\n",
      "Neg\n",
      "Exp_1\n",
      "Add_2/x\n",
      "Add_2\n",
      "truediv_2/x\n",
      "truediv_2\n",
      "Const_7\n",
      "Reshape/shape\n",
      "Reshape\n",
      "Const_8\n",
      "Reshape_1/shape\n",
      "Reshape_1\n",
      "Const_9\n",
      "MatMul\n",
      "Mul_1\n",
      "zeros\n",
      "zeros_like\n",
      "ones_like/Shape\n",
      "ones_like/Const\n",
      "ones_like\n",
      "Fill/dims\n",
      "Fill/value\n",
      "Fill\n",
      "LinSpace/start\n",
      "LinSpace/stop\n",
      "LinSpace/num\n",
      "LinSpace\n",
      "range/start\n",
      "range/limit\n",
      "range/delta\n",
      "range\n",
      "random_normal/shape\n",
      "random_normal/mean\n",
      "random_normal/stddev\n",
      "random_normal/RandomStandardNormal\n",
      "random_normal/mul\n",
      "random_normal\n",
      "truncated_normal/shape\n",
      "truncated_normal/mean\n",
      "truncated_normal/stddev\n",
      "truncated_normal/TruncatedNormal\n",
      "truncated_normal/mul\n",
      "truncated_normal\n",
      "random_uniform/shape\n",
      "random_uniform/min\n",
      "random_uniform/max\n",
      "random_uniform/RandomUniform\n",
      "random_uniform/sub\n",
      "random_uniform/mul\n",
      "random_uniform\n",
      "Variable/initial_value\n",
      "Variable\n",
      "Variable/Assign\n",
      "Variable/read\n",
      "Variable_1/initial_value\n",
      "Variable_1\n",
      "Variable_1/Assign\n",
      "Variable_1/read\n",
      "zeros_1/shape_as_tensor\n",
      "zeros_1/Const\n",
      "zeros_1\n",
      "Variable_2\n",
      "Variable_2/Assign\n",
      "Variable_2/read\n",
      "init\n",
      "init_1\n",
      "Variable_3/initial_value\n",
      "Variable_3\n",
      "Variable_3/Assign\n",
      "Variable_3/read\n",
      "Assign/value\n",
      "Assign\n",
      "Assign_1/value\n",
      "Assign_1\n",
      "AssignAdd/value\n",
      "AssignAdd\n",
      "AssignSub/value\n",
      "AssignSub\n",
      "name_scope/Variable/initial_value\n",
      "name_scope/Variable\n",
      "name_scope/Variable/Assign\n",
      "name_scope/Variable/read\n",
      "name_scope/Variable_1/initial_value\n",
      "name_scope/Variable_1\n",
      "name_scope/Variable_1/Assign\n",
      "name_scope/Variable_1/read\n",
      "var_scope/Variable/initial_value\n",
      "var_scope/Variable\n",
      "var_scope/Variable/Assign\n",
      "var_scope/Variable/read\n",
      "var_scope/Variable_1/initial_value\n",
      "var_scope/Variable_1\n",
      "var_scope/Variable_1/Assign\n",
      "var_scope/Variable_1/read\n",
      "Placeholder\n",
      "Placeholder_1\n",
      "Placeholder_2\n",
      "Square\n"
     ]
    }
   ],
   "source": [
    "for op in g.get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello'\n"
     ]
    }
   ],
   "source": [
    "what_is_this = g.get_tensor_by_name('Hello:0')\n",
    "print(what_is_this.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成新图\n",
    "上面介绍了`tensorflow`运行程序时的默认图, 那么我们可以构造有别于默认图的新图吗? 当然可以的, 通过**`g1=tf.Graph()`**就可以办到. 但这并没有结束, 我们需要将这个图设置为我们构造`tensor`以及`op`的默认图, 让程序能够理解我们将要定义的`tensor`到底在哪个图里定义, 因此我们还需要通过`python`的`with`语句来确立图的作用范围.然后我们可以通过变量的`.graph`属性来确定它在哪个图中, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1:  <tensorflow.python.framework.ops.Graph object at 0x0000019F703C4748>\n",
      "default_graph:  <tensorflow.python.framework.ops.Graph object at 0x0000019F701CBA90>\n",
      "default_graph:  <tensorflow.python.framework.ops.Graph object at 0x0000019F701CBA90>\n",
      "a.graph:  <tensorflow.python.framework.ops.Graph object at 0x0000019F701CBA90>\n",
      "a1.graph:  <tensorflow.python.framework.ops.Graph object at 0x0000019F701CBA90>\n",
      "a2.graph:  <tensorflow.python.framework.ops.Graph object at 0x0000019F703C4748>\n"
     ]
    }
   ],
   "source": [
    "##定义一个新图, 注意它和之前的g有什么不同\n",
    "g1 = tf.Graph()\n",
    "print('g1: ', g1)\n",
    "\n",
    "##将这个新图作为默认图,注意前后默认图有没有不同\n",
    "print('default_graph: ', tf.get_default_graph())\n",
    "g1.as_default()\n",
    "print('default_graph: ', tf.get_default_graph())\n",
    "\n",
    "##在这个新图后面定义新的`tensor`\n",
    "a1 = tf.constant(32, name='a1')\n",
    "\n",
    "with g1.as_default():\n",
    "    a2 = tf.constant(32, name='a2')\n",
    "\n",
    "##查看`tensor`从属的图\n",
    "print('a.graph: ', a.graph)\n",
    "print('a1.graph: ', a1.graph)\n",
    "print('a2.graph: ', a2.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图的可视化\n",
    "现在我们要迫不及待的给大家介绍`tensorflow`的一款神器**`tensorboard`**!它在我们安装`tensorflow`的过程中就已经被自动安装了, 非常方便.\n",
    "\n",
    "在它的帮助下, 我们可以将刚才我们构造的图可视化, 让它变得更加清晰直观.\n",
    "\n",
    "- 首先我们需要将我们想要可视化的图导入到`tensorboard`可以解析的文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    graph_writer = tf.summary.FileWriter('.', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个时候在当前目录中你就会多一个`events.*`的文件, 这个就是需要的文件.\n",
    "\n",
    "- 然后我们在当前目录打开终端(一般来说是右键, 点击`Open in New Terminal`或者是`在终端中打开`),键入以下命令:\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=.\n",
    "```\n",
    "\n",
    "- 然后就会有一个这样的输出\n",
    "\n",
    "```\n",
    "$ TensorBoard 0.1.8 at http://USERNAME:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "- 然后我们打开浏览器（用chrome浏览器）, 输入`at`后面的链接`http://USERNAME:6006`,进入.你就会发现这样的界面\n",
    "\n",
    "<img src=\"https://image.ibb.co/juk2iH/tensorboard_graph.png\">\n",
    "\n",
    "- 然后我们就可以尽情的探索里面的内容了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结语\n",
    "至此, 我们完成了`tensorflow`的初步概览. 接下来我们将要进入深度学习环节."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "251px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
