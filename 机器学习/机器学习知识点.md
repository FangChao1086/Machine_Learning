# 机器学习知识点

* [偏差与方差](#偏差与方差)
* [生成模型与判别模型](#生成模型与判别模型)
* [特征选择方法](#特征选择方法)
* [不平衡类别问题](#不平衡类别问题)
* [过拟合的解决办法](#过拟合的解决办法)

<span id="偏差与方差"></span>
## 偏差与方差
* 偏差(Bias)：模型**预测的期望值**与**真实值**之间的差距，描述模型的**拟合能力**    
  * 高偏差的解决方案：boosting，复杂化模型，更多特征  
  ![偏差](https://github.com/FangChao1086/Machine_learning/blob/master/素材/1.png#pic_center)  
* 方差(Variance)：模型**预测的期望值**与**预测值**之间的差平方和，描述模型的**稳定性**   
  * 高方差的解决方案：bagging，模型简化，降维更少特征  
  ![方差](https://github.com/FangChao1086/Machine_learning/blob/master/素材/2.png#pic_center)  
  ![方差](https://github.com/FangChao1086/Machine_learning/blob/master/素材/3.png#pic_center)

<span id="生成模型与判别模型"></span>
## 生成模型与判别模型
* 判别模型：**直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型**；不考虑样本的产生模型   
  * 优缺点：能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪   
* 生成模型：**学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型**；P(Y|X)= P(X,Y)/ P(X),其中P(x)是训练数据的概率分布
  * 优缺点：不能反映训练数据本身的特性。但它寻找不同类别之间的最优分类面  
  
**由生成模型可以得到判别模型，但由判别模型得不到生成模型**

&emsp;&emsp;**生成算法尝试去找到底这个数据是怎么产生的**，然后再对一个信号进行分类。基于你的生成假设，那么那个类别最有可能产生这个信号，这个信号就属于那个类别。**判别模型不关心数据是怎么生成的，它只关心信号之间的差别**，然后用差别来简单对给定的一个信号进行分类。

<span id="特征选择方法"></span>
## 特征选择方法
* **Filter**：**过滤法**
  * 按照**发散性**或者**相关性**对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征
* **Wrapper**:**包装法**
  * 根据**目标函数**（通常是预测效果评分），每次选择若干特征，或者排除若干特征
* **Embedded**:**嵌入法**
  * 先使用某些**机器学习的算法和模型进行训练**，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣
### Filter
* **1、移除低方差的特征**
  * 当特征值都是离散型变量的时候这种方法才能用，如果是连续型变量，就需要将连续变量离散化之后才能用；假设某特征的特征值只有0和1，并且在所有输入样本中，95%的实例的该特征取值都是1，可以认为这个特征作用不大。当100%都是1，那这个特征就没意义
* **2、单变量特征选择（独立的衡量每个特征与响应变量之间的关系）**
  * **2.1、卡方（Chi2）检验**
  * **2.2、皮尔森相关系数**
    * 衡量的是变量之间的线性相关性 结果的取值区间为[-1，1]  
    * 缺陷：只对线性关系敏感。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近0
  * **2.3、互信息和最大信息系数**
  * **2.4、距离相关系数**
    * 为了克服Pearson相关系数的弱点  
    * 在x和x^2这个例子中，即便Pearson相关系数是0，我们也不能断定这两个变量是独立的（有可能是非线性相关）；但如果距离相关系数是0，那么我们就可以说这两个变量是独立的。
  * **2.5、基于模型的特征排序**
    * 这种方法的思路是直接使用你要用的**机器学习算法**，**针对每个单独的特征和响应变量建立预测模型**。假如特征和响应变量之间的关系是非线性的，可以用基于树的方法(决策树、随机森林)、或者扩展的线性模型等。基于树的方法比较易于使用，因为他们对非线性关系的建模比较好，并且不需要太多的调试。但要注意过拟合问题，因此树的深度最好不要太大，再就是运用交叉验证。
### Wrapper
* **3、递归特征消除**
  * 使用一个基模型来进行多轮训练，每轮训练后，移除若干权值系数（绝对值权重小）的特征，再基于新的特征集进行下一轮训练
### Embedded
* **4、使用SelectFromModel选择特征**
  * **4.1、基于L1的特征选择**
    * 使用L1范数作为惩罚项的线性模型(Linear models)会得到稀疏解：大部分特征对应的系数为0。当你希望减少特征的维度以用于其它分类器时，可以通过 feature_selection.SelectFromModel 来选择不为0的系数。特别指出，常用于此目的的稀疏预测模型有 linear_model.Lasso（回归）， linear_model.LogisticRegression 和 svm.LinearSVC（分类）
  * **4.2、随机稀疏模型**
    * 基于L1的稀疏模型的局限在于，当**面对一组互相关的特征时**，它们只会选择其中一项特征。为了减轻该问题的影响可以使用随机化技术，通过_多次重新估计稀疏模型来扰乱设计矩阵_，或通过_多次下采样数据来统计一个给定的回归量被选中的次数
  * **4.3、基于树的特征选择**
    * 基于树的预测模型（见 sklearn.tree 模块，森林见 sklearn.ensemble 模块）能够用来计算特征的重要程度，因此能用来去除不相关的特征（结合 sklearn.feature_selection.SelectFromModel）
* **5、将特征选择过程融入pipeline**
  * 在此代码片段中，将　sklearn.svm.LinearSVC 和 sklearn.feature_selection.SelectFromModel 结合来评估特征的重要性，并选择最相关的特征。之后 sklearn.ensemble.RandomForestClassifier 模型使用转换后的输出训练，即只使用被选出的相关特征  
  ![将特征选择过程融入pipeline](https://github.com/FangChao1086/Machine_learning/blob/master/素材/6.png)

<span id="不平衡类别问题"></span>
## 不平衡类别问题
>举例  
1.欺诈预测（欺诈的数量远远小于真实交易的数量）  
2.自然灾害预测（不好的事情远远小于好的事情）  
3.在图像分类中识别恶性肿瘤（训练样本中含有肿瘤的图像远比没有肿瘤的图像少）  

不平衡类别会造成问题有两个主要原因：   
1.对于不平衡类别，我们**不能得到实时的最优结果**，因为模型/算法从来没有充分地考察隐含类。  
2.它对验证和测试样本的获取造成了一个问题，因为**在一些类观测极少的情况下，很难在类中有代表性**  

* **解决方法**
  * **欠采样**
    * **去除一些多数类中的样本使得正例、反例数目接近**。虽然这种方法使用起来非常简单，但很有可能被我们删除了的数据包含着预测类的重要信息。
  * **过采样**
    * **增加一些少数类样本使得正、反例数目接近**。理想情况下这种方法给了我们足够的样本数，但过采样可能导致过拟合训练数据。
  * **合成采样（SMOTE）**
    * **解决的问题：一个类别的观测数量极度稀少时该怎么做**
    * **算法：对每个少数类样本x_i，从它的最近邻中随机选择一个样本x ̂_i（x ̂_i是少数类中的一个样本），然后在x_i和 x ̂_i之间的连线上随机选择一点作为新合成的少数类样本**
    * **缺点：生成的少数类样本容易与周围的多数类样本产生重叠难以分类**
    
>下采样：  
>>对于一个不均衡的数据，让目标值(如0和1分类)中的样本数据量相同，且以数据量少的一方的样本数量为准。    

>上采样：  
>>以数据量多的一方的样本数量为标准，把样本数量较少的类的样本数量生成和样本数量多的一方相同，称为上采样。

<span id="过拟合的解决办法"></span>
## 过拟合的解决办法
* 增加训练数据，可以采用数据增强的方法
* 正则化
  * （L1,L2正则化）
* 交叉验证
* 特征选择/特征降维
* Dropout
  * （让神经元以超参数P的概率被激活）
* 早停early stopping
  * （比如交叉验证中，错误率最小泛化性能最好，此时如果训练集错误率还在继续下降，但也得提前终止训练）
* batch normalization
  * （对该层的输出做批标准化，使下层的输入接近高斯分布）
* 降低模型复杂度
*	Bagging
